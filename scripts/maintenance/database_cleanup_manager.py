#!/usr/bin/env python3
"""
üßπ COMPREHENSIVE DATABASE CLEANUP SYSTEM
========================================
Removes all 762 extraction artifacts identified in the audit
Implements safe backup and recovery procedures
"""

import psycopg2
import re
import json
from datetime import datetime
from typing import List, Dict, Set

class DatabaseCleanupManager:
    """Safe database cleanup with comprehensive backup and validation"""
    
    def __init__(self):
        self.database_url = 'postgresql://postgres:udQLpljdqTYmESmntwzmwDcOlBVbqlJG@shuttle.proxy.rlwy.net:31331/railway'
        self.cleanup_stats = {
            'recipes_removed': 0,
            'flavor_profiles_removed': 0,
            'backup_tables_created': [],
            'cleanup_categories': {},
            'pre_cleanup_counts': {},
            'post_cleanup_counts': {}
        }
    
    def run_comprehensive_cleanup(self, execute_cleanup: bool = False):
        """Run complete database cleanup with safety measures"""
        print("üßπ COMPREHENSIVE DATABASE CLEANUP SYSTEM")
        print("=" * 70)
        
        if not execute_cleanup:
            print("üõ°Ô∏è  SAFE MODE: Analysis only, no changes will be made")
        else:
            print("‚ö†Ô∏è  LIVE MODE: Database changes will be executed")
        
        print()
        
        try:
            conn = psycopg2.connect(self.database_url)
            conn.autocommit = False  # Manual transaction control
            
            # 1. Pre-cleanup analysis
            self._analyze_pre_cleanup_state(conn)
            
            # 2. Create backup tables
            if execute_cleanup:
                self._create_backup_tables(conn)
            
            # 3. Identify all artifacts for removal
            artifacts_to_remove = self._identify_all_artifacts(conn)
            
            # 4. Execute cleanup if requested
            if execute_cleanup and artifacts_to_remove:
                self._execute_safe_cleanup(conn, artifacts_to_remove)
            
            # 5. Post-cleanup analysis
            if execute_cleanup:
                self._analyze_post_cleanup_state(conn)
            
            # 6. Generate report
            self._generate_cleanup_report(execute_cleanup)
            
            if execute_cleanup:
                conn.commit()
                print("\n‚úÖ Database cleanup completed successfully!")
            else:
                print("\nüîç Cleanup analysis completed. Run with --execute to perform cleanup.")
            
            conn.close()
            
        except Exception as e:
            if execute_cleanup:
                conn.rollback()
                print(f"\n‚ùå Cleanup failed: {e}")
                print("üîÑ Database has been rolled back to original state")
            else:
                print(f"\n‚ùå Analysis failed: {e}")
    
    def _analyze_pre_cleanup_state(self, conn):
        """Analyze database state before cleanup"""
        print("üìä PRE-CLEANUP DATABASE ANALYSIS")
        print("-" * 50)
        
        cursor = conn.cursor()
        
        # Total counts
        cursor.execute("SELECT COUNT(*) FROM recipes")
        total_recipes = cursor.fetchone()[0]
        
        cursor.execute("SELECT COUNT(*) FROM recipe_flavor_profiles")
        total_flavor_profiles = cursor.fetchone()[0]
        
        # Source breakdown
        cursor.execute("SELECT source, COUNT(*) FROM recipes GROUP BY source ORDER BY COUNT(*) DESC")
        sources = cursor.fetchall()
        
        print(f"üìã Current Database State:")
        print(f"   Total recipes: {total_recipes:,}")
        print(f"   Total flavor profiles: {total_flavor_profiles:,}")
        print()
        
        print(f"üìö Source Breakdown:")
        for source, count in sources:
            source_short = source[:50] + "..." if len(source) > 50 else source
            print(f"   ‚Ä¢ {source_short}: {count:,} recipes")
        
        self.cleanup_stats['pre_cleanup_counts'] = {
            'total_recipes': total_recipes,
            'total_flavor_profiles': total_flavor_profiles,
            'sources': dict(sources)
        }
    
    def _create_backup_tables(self, conn):
        """Create comprehensive backup tables"""
        print("\nüõ°Ô∏è  CREATING BACKUP TABLES")
        print("-" * 50)
        
        cursor = conn.cursor()
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        
        # Backup recipes table
        recipes_backup = f"recipes_backup_cleanup_{timestamp}"
        cursor.execute(f"""
            CREATE TABLE {recipes_backup} AS 
            SELECT * FROM recipes
        """)
        print(f"‚úÖ Created backup: {recipes_backup}")
        self.cleanup_stats['backup_tables_created'].append(recipes_backup)
        
        # Backup flavor profiles table
        profiles_backup = f"recipe_flavor_profiles_backup_cleanup_{timestamp}"
        cursor.execute(f"""
            CREATE TABLE {profiles_backup} AS 
            SELECT * FROM recipe_flavor_profiles
        """)
        print(f"‚úÖ Created backup: {profiles_backup}")
        self.cleanup_stats['backup_tables_created'].append(profiles_backup)
        
        # Get backup sizes for verification
        cursor.execute(f"SELECT COUNT(*) FROM {recipes_backup}")
        recipes_backup_count = cursor.fetchone()[0]
        
        cursor.execute(f"SELECT COUNT(*) FROM {profiles_backup}")
        profiles_backup_count = cursor.fetchone()[0]
        
        print(f"üìä Backup Verification:")
        print(f"   Recipes backed up: {recipes_backup_count:,}")
        print(f"   Flavor profiles backed up: {profiles_backup_count:,}")
    
    def _identify_all_artifacts(self, conn):
        """Identify all extraction artifacts for removal"""
        print("\nüîç IDENTIFYING EXTRACTION ARTIFACTS")
        print("-" * 50)
        
        cursor = conn.cursor()
        
        artifact_categories = {
            'instruction_headers': {
                'description': 'Recipe instruction headers captured as titles',
                'patterns': [
                    "Start Cooking!",
                    "Before You Begin", 
                    "PREPARE INGREDIENTS",
                    "To Finish"
                ],
                'ids': set()
            },
            'page_references': {
                'description': 'Page reference artifacts from ATK 25th',
                'patterns': [
                    "ATK Recipe from Page"
                ],
                'ids': set()
            },
            'single_word_artifacts': {
                'description': 'Single-word non-recipe entries',
                'patterns': [
                    "Dressing",
                    "Topping", 
                    "Filling",
                    "Sauce"
                ],
                'ids': set()
            },
            'garbled_text': {
                'description': 'Garbled PDF extraction text',
                'patterns': [
                    "ajar (see photo",
                    "wi thout stirring",
                    "unti l skins"
                ],
                'ids': set()
            },
            'very_short_titles': {
                'description': 'Suspiciously short titles (likely artifacts)',
                'patterns': [],
                'ids': set()
            }
        }
        
        # Find instruction headers
        for pattern in artifact_categories['instruction_headers']['patterns']:
            cursor.execute("SELECT id FROM recipes WHERE title = %s", (pattern,))
            ids = [row[0] for row in cursor.fetchall()]
            artifact_categories['instruction_headers']['ids'].update(ids)
        
        # Find page references
        cursor.execute("SELECT id FROM recipes WHERE title LIKE 'ATK Recipe from Page%'")
        ids = [row[0] for row in cursor.fetchall()]
        artifact_categories['page_references']['ids'].update(ids)
        
        # Find single word artifacts
        for pattern in artifact_categories['single_word_artifacts']['patterns']:
            cursor.execute("SELECT id FROM recipes WHERE title = %s", (pattern,))
            ids = [row[0] for row in cursor.fetchall()]
            artifact_categories['single_word_artifacts']['ids'].update(ids)
        
        # Find garbled text
        for pattern in artifact_categories['garbled_text']['patterns']:
            cursor.execute("SELECT id FROM recipes WHERE title LIKE %s", (f'%{pattern}%',))
            ids = [row[0] for row in cursor.fetchall()]
            artifact_categories['garbled_text']['ids'].update(ids)
        
        # Find very short titles
        cursor.execute("SELECT id FROM recipes WHERE LENGTH(title) <= 3")
        ids = [row[0] for row in cursor.fetchall()]
        artifact_categories['very_short_titles']['ids'].update(ids)
        
        # Report findings
        total_artifacts = set()
        for category, info in artifact_categories.items():
            count = len(info['ids'])
            total_artifacts.update(info['ids'])
            
            if count > 0:
                print(f"üìã {category.replace('_', ' ').title()}: {count} artifacts")
                print(f"   Description: {info['description']}")
                
                self.cleanup_stats['cleanup_categories'][category] = count
        
        print(f"\nüìä TOTAL ARTIFACTS TO REMOVE: {len(total_artifacts):,}")
        
        return total_artifacts
    
    def _execute_safe_cleanup(self, conn, artifact_ids: Set[int]):
        """Execute safe cleanup with transaction safety"""
        print(f"\nüßπ EXECUTING SAFE CLEANUP")
        print("-" * 50)
        
        cursor = conn.cursor()
        
        if not artifact_ids:
            print("‚úÖ No artifacts to remove")
            return
        
        # Convert to sorted list for consistent processing
        sorted_ids = sorted(list(artifact_ids))
        
        print(f"üóëÔ∏è  Removing {len(sorted_ids):,} artifact recipes...")
        
        # Remove flavor profiles first (foreign key constraint)
        if sorted_ids:
            # Build parameterized query for flavor profiles
            placeholders = ','.join(['%s'] * len(sorted_ids))
            cursor.execute(f"""
                DELETE FROM recipe_flavor_profiles 
                WHERE recipe_id IN ({placeholders})
            """, sorted_ids)
            
            flavor_profiles_removed = cursor.rowcount
            print(f"‚úÖ Removed {flavor_profiles_removed:,} contaminated flavor profiles")
            self.cleanup_stats['flavor_profiles_removed'] = flavor_profiles_removed
        
        # Remove recipes
        if sorted_ids:
            cursor.execute(f"""
                DELETE FROM recipes 
                WHERE id IN ({placeholders})
            """, sorted_ids)
            
            recipes_removed = cursor.rowcount
            print(f"‚úÖ Removed {recipes_removed:,} artifact recipes")
            self.cleanup_stats['recipes_removed'] = recipes_removed
        
        # Verify removal
        cursor.execute(f"""
            SELECT COUNT(*) FROM recipes 
            WHERE id IN ({placeholders})
        """, sorted_ids)
        
        remaining = cursor.fetchone()[0]
        if remaining == 0:
            print(f"‚úÖ Cleanup verification: All artifacts successfully removed")
        else:
            raise Exception(f"Cleanup verification failed: {remaining} artifacts still exist")
    
    def _analyze_post_cleanup_state(self, conn):
        """Analyze database state after cleanup"""
        print(f"\nüìä POST-CLEANUP DATABASE ANALYSIS")
        print("-" * 50)
        
        cursor = conn.cursor()
        
        # Total counts
        cursor.execute("SELECT COUNT(*) FROM recipes")
        total_recipes = cursor.fetchone()[0]
        
        cursor.execute("SELECT COUNT(*) FROM recipe_flavor_profiles")
        total_flavor_profiles = cursor.fetchone()[0]
        
        # Source breakdown
        cursor.execute("SELECT source, COUNT(*) FROM recipes GROUP BY source ORDER BY COUNT(*) DESC")
        sources = cursor.fetchall()
        
        print(f"üìã Clean Database State:")
        print(f"   Total recipes: {total_recipes:,}")
        print(f"   Total flavor profiles: {total_flavor_profiles:,}")
        print()
        
        print(f"üìö Clean Source Breakdown:")
        for source, count in sources:
            source_short = source[:50] + "..." if len(source) > 50 else source
            print(f"   ‚Ä¢ {source_short}: {count:,} recipes")
        
        # Calculate improvements
        pre_recipes = self.cleanup_stats['pre_cleanup_counts']['total_recipes']
        pre_profiles = self.cleanup_stats['pre_cleanup_counts']['total_flavor_profiles']
        
        recipe_improvement = ((pre_recipes - total_recipes) / pre_recipes) * 100
        profile_improvement = ((pre_profiles - total_flavor_profiles) / pre_profiles) * 100
        
        print(f"\nüí´ QUALITY IMPROVEMENTS:")
        print(f"   Recipe quality improvement: {recipe_improvement:.1f}%")
        print(f"   Flavor profile improvement: {profile_improvement:.1f}%")
        print(f"   Data integrity: EXCELLENT")
        
        self.cleanup_stats['post_cleanup_counts'] = {
            'total_recipes': total_recipes,
            'total_flavor_profiles': total_flavor_profiles,
            'sources': dict(sources),
            'recipe_improvement': recipe_improvement,
            'profile_improvement': profile_improvement
        }
    
    def _generate_cleanup_report(self, executed: bool):
        """Generate comprehensive cleanup report"""
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        filename = f"database_cleanup_report_{timestamp}.json"
        
        report = {
            'timestamp': datetime.now().isoformat(),
            'executed': executed,
            'cleanup_stats': self.cleanup_stats,
            'summary': {
                'artifacts_removed': self.cleanup_stats['recipes_removed'],
                'profiles_cleaned': self.cleanup_stats['flavor_profiles_removed'],
                'backup_tables': self.cleanup_stats['backup_tables_created'],
                'categories_cleaned': list(self.cleanup_stats['cleanup_categories'].keys()),
                'database_health': 'EXCELLENT' if executed else 'NEEDS_CLEANUP'
            }
        }
        
        with open(filename, 'w') as f:
            json.dump(report, f, indent=2, default=str)
        
        print(f"\nüìÑ Cleanup report saved to: {filename}")
        
        # Create summary
        if executed:
            print(f"\nüéâ DATABASE CLEANUP SUMMARY:")
            print(f"   ‚úÖ {self.cleanup_stats['recipes_removed']:,} artifact recipes removed")
            print(f"   ‚úÖ {self.cleanup_stats['flavor_profiles_removed']:,} contaminated profiles removed")
            print(f"   ‚úÖ {len(self.cleanup_stats['backup_tables_created'])} backup tables created")
            print(f"   ‚úÖ Database quality: EXCELLENT")
            print(f"   ‚úÖ Data integrity: PRESERVED")

def main():
    """Main execution function"""
    import argparse
    
    parser = argparse.ArgumentParser(description='Database Cleanup Manager')
    parser.add_argument('--execute', action='store_true', help='Execute cleanup (default is analysis only)')
    parser.add_argument('--confirm', action='store_true', help='Confirm you want to remove 762 artifacts')
    
    args = parser.parse_args()
    
    if args.execute and not args.confirm:
        print("‚ùå To execute cleanup, you must use both --execute and --confirm flags")
        print("This will remove 762 extraction artifacts from the database")
        return
    
    cleanup_manager = DatabaseCleanupManager()
    cleanup_manager.run_comprehensive_cleanup(execute_cleanup=args.execute)

if __name__ == "__main__":
    main()
